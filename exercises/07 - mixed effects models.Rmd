---
title: "07 - mixed effects models"
author: "Jenny Bigman"
date: "5/12/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(nlme, lme4, tidyverse, here)

morph <- read_csv(here("./data/morph.csv")) %>%
	mutate(log_beakh = log10(beakh),
				 log_wingl = log10(wingl))

```

Mixed effects models are also called:

Random effects models
Hierarchical models
Multilevel models
Repeated measures models 


They are useful when you have certain predictors that you need to account for and that you think affect the response variable. Sometimes, these are nested factors (site, plot, quadrat, tank, etc., population). I often use them when I have multiple species. The key is that the randon effect removes variation in the residuals!

My favorite visual for this is from: http://mfviz.com/hierarchical-models/. 

Let's look at this together.

Ok, let's dive into this, first looking at just random intercepts with our morph data. For this, we will go back to our question of beak height and wing length. 

First, let's plot (the first rule of an data analysis!)
```{r}
ggplot() +
	geom_point(data = morph, aes(log_wingl, log_beakh))
```

Let's color this by species.
```{r}
ggplot() +
	geom_point(data = morph, aes(log_wingl, log_beakh, color = taxon))
```

It looks like there are a few species with 1 or 2 observations. We want to remove these for our purposes because we are going to be fitting separate relationships -- through mixed effects models -- for a given taxon. You need at least 3 points to fit a line, and even then, you should have more! 

```{r}
morph <- morph %>%
	group_by(taxon) %>%
	filter(n()>=3) %>%
	mutate(log_wingl = log10(wingl),
				 log_beakh = log10(beakh))
```

Let's replot.
```{r}
ggplot() +
	geom_point(data = morph, aes(log_wingl, log_beakh, color = taxon))
```

Wow, it really looks like we have a pattern by species. 


You could fit a separate model for each species. But, that is not the best approach. Any ideas why?

These species are closely related and likely have similar morphology. By using a mixed effects model, we employ something called partial pooling, where we are sharing information among the groups. Specifically, there will be a 'group-level' intercept (one for each species in our case) and a 'population-level' intercept (statistical, not ecological population). The group-level intercepts are drawn from a distribution that has a mean of the population-level intercept (in not so statistical terms, the group-level intercept is bounded so to speak by the population level intercept).

Going back to the plot, it looks like each species would have a different intercept, or, that each species varies in their beak height at a given wing length. We can fit a mixed effects model with a random intercept, allowing each species to vary in their beak height at a given wing length.

There are two packages for mixed effects models. nlme and lme4. You can use either and you should get a very similar (if not identical) result. However, the syntax is different for model between the packages.

The basic syntax for random intercepts:

### nlme::lme()   
y ~ x, random = ~1 | group   
y ~ x, random = ~1 + x | group   
y ~ x, random = ~1 | group/subgroup   
y ~ x, random = list(1 = ~group, 1 = ~subgroup)  

### lme4::lmer()   
y ~ x + (1 | group)   
y ~ x + (1 + x | group)   
y ~ x + (1 | group/subgroup)   
y ~ x + (1 | group) + (1 | group:subgroup)  

```{r}
ran_int <-  lmer(log_beakh ~ log_wingl + (1 | taxon), data = morph)

summary(ran_int)
```

Notice the new piece `+ (1 | taxon)`. The `1` refers to "intercept" and the `| taxon` tells the function that you want to let the intercept vary by the values in the `taxon` column.

What does the output of the model tell us? How does it differ from our lm() models?

What if we wanted to see the group-level intercepts?
```{r}
ranef(ran_int)
```

# Plotting the predictions

Let's plot our model and fitted values To do that, we'll use the `predict` function like we did for lm(). Because we are applying it to an object of class `merMod` (meaning it was created by the `lmer` function), we can get details on that function at `?predict.merMod`.

Here, I am just going to add these fitted values back into the dataset and streamline the process now that you know how to do this.
```{r}
morph$ran_int_fits <- predict(ran_int)
head(morph)

ggplot(morph, aes(log_wingl, log_beakh, colour = taxon)) +
  geom_point(alpha = 0.1) + # alpha = 0.1 make 10% opaque
  geom_line(aes(y = ran_int_fits))
```

There is another kind of prediction we can make with a mixed effects model. We can make a prediction at the population-level. This is our expectation if we sampled a new taxon of unknown identity. With the lme4 package, we can do that by adding the argument `re.form = NA` to the `predict` function:

```{r}
morph$ran_int_pop <- predict(ran_int, re.form = NA)
```

We can add the population prediction to the plot in black with a thicker line:

```{r}
ggplot(morph, aes(log_wingl, log_beakh, colour = taxon)) +
  geom_point(alpha = 0.1) + # alpha = 0.1 make 10% opaque
  geom_line(aes(y = ran_int_fits)) +
  geom_line(aes(y = ran_int_pop), colour = "black", size = 1) 
```

This black line is called the population estimate, irrespective of species identity; it is the prediction for a new taxon.

Let's go back to the random effects and plot them. We can extract them from the 'ranef()' function we used earlier using a little dplyr magic.
Let's try plotting them. We'll use a little dplyr magic to make a nice data frame.
```{r}
 # row.names(.) means the row names of the data frame:

ran_effs_int <- ranef(ran_int)$taxon %>% 
	mutate(taxon = row.names(.)) %>% 
  rename(intercept = `(Intercept)`) # a nicer column name

ggplot(ran_effs_int, aes(x = 1, y = intercept)) + geom_point(alpha = 0.7)
```

What is the mean of these random intercepts?
```{r}
mean(ranef(ran_int)$taxon[, 1])
```

This mean should be close to 0 and it is. Is that what you expected? Why or why not?

And what are the estimates of the main effects?
```{r}
fixef(ran_int)
fixef(ran_int)[[1]]
fixef(ran_int)[[2]]
```

So the intercept estimate for each taxon is equal to the "fixed effect" intercept plus the "random" deviation.

We can get the intercept estimates for each taxon in a couple of ways. First, we can combine the 2 values we just accessed. 

```{r}
fixef(ran_int)[[1]] + ranef(ran_int)$taxon
```

Second, we can use the function `coef` to combine them for us.

```{r}
coef(ran_int)
```

Let's go back to our `summary(ran_int)`. What are the important parts? We already looked at the coefficients estimates. Now, what's this bit at the top
The following are the important pieces:

```{}
Random effects:
 Groups   Name        Variance Std.Dev.
 taxon    (Intercept) 0.002959 0.05440 
 Residual             0.000633 0.02516 
Number of obs: 197, groups:  taxon, 7
```

First, the 0.002959 is the spread of the random intercepts and 0.05440 is the standard deviation of this spread. This shows us how different intercepts are across the groups.

The residual variance and standard deviation (0.000633 and 0.02515) is the unexplained variability left in the data after we subtract off our model.

One check to see whether it is worth including the random effect is whether the residual variance is > than 
the random effect variance. If so, likely don't need to include it. (here, 0.000633 < 0.002959, so we should include it).

Another part of the summary tells us whether our the slope and intercept of our fixed effects are correlated. Here, our slope and intercept are VERY correlated. For this issue, you will want to center, standardize, or scale (both center and standarize) you predictor variables. I won't go into this for time, but there are excellent papers on this (e.g., see https://besjournals.onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2010.00012.x). And here is blog post from Sean Anderson (stats genius!): https://seananderson.ca/2014/07/30/centering-interactions/. 

```{}
Correlation of Fixed Effects:
           (Intr)
log_wingl -0.996
```

Ok, let's move on to random intercepts AND slopes. 

Let's go back to our plot. 
```{r}
ggplot() +
	geom_point(data = morph, aes(log_wingl, log_beakh, color = taxon))
```

It does look the slopes are different by species. The question here is whether the relationship between beak height and wing length differs by species (this includes the different intercept -- whether beak height for a given wing length differs by species, although it is always good to just explicitly say this.)

In our last mixed effects model (`lmer(log_beakh ~ log_wingl + (1 | taxon), data = morph)`), we assumed that the slopes were constant across taxa. Now, let's let them vary by taxa. 

```{r, message = FALSE}

ran_slope <-  lmer(log_beakh ~ log_wingl + (1 + log_wingl | taxon), data = morph)
```

The `(1 + log_wingl | taxon)` means random slopes and intercepts. We don't have to write the `1+`, so we can just write `(log_wingl | taxon)`.

Let's look at the summary. What is different?
```{r}
summary(ran_slope)

summary(ran_int)
```

Let's predict and plot.
```{r}
morph$ran_slope_fits <- predict(ran_slope)
head(morph)

ggplot(morph, aes(log_wingl, log_beakh, colour = taxon)) +
  geom_point(alpha = 0.1) + # alpha = 0.1 make 10% opaque
  geom_line(aes(y = ran_slope_fits))

# save this for next lesson

mem_plot1 <- 
	ggplot(morph, aes(log_wingl, log_beakh, colour = taxon)) +
  geom_point(alpha = 0.1) + # alpha = 0.1 make 10% opaque
  geom_line(aes(y = ran_slope_fits))

ggsave(mem_plot1, file = "mem_plot1.png",
			 width = 5, height = 5, units = "in")

```

That looks great! We can see that the fit lines now fit the data well. Let's add a population-level fit line.

```{r}
morph$ran_slope_pop <- predict(ran_slope, re.form = NA)
```

We can add the population prediction to the plot in black with a thicker line:

```{r}
ggplot(morph, aes(log_wingl, log_beakh, colour = taxon)) +
  geom_point(alpha = 0.1) + # alpha = 0.1 make 10% opaque
  geom_line(aes(y = ran_slope_fits)) +
  geom_line(aes(y = ran_slope_pop), colour = "black", size = 1) 
```

Now, let's walk through how extract the coefficients using the broom.mixed package. The broom package deals with models from lm() (and a few other functions/packages). Here we have to use the `broom.mixed` package for mixed effects models from lme4. We will play with the `broommixed::tidy`, which returns information about parameter estimates in a tidy data frame, and the function `broom.mixed::augment`, which returns a tidy data frame of predictions, residuals, and other useful columns.


```{r}
# extract fixed effects
broom.mixed::tidy(ran_int, conf.int = TRUE)
broom.mixed::tidy(ran_slope, conf.int = TRUE)

# extract random effects
aug_int <- broom.mixed::augment(ran_int, conf.int = TRUE)
aug_slope <- broom.mixed::augment(ran_slope, conf.int = TRUE)

```

We will use these functions to check our assumptions. First, let's check residuals against the fitted values. 

```{r, warning=FALSE, message=FALSE}
# for the random intercept model
ggplot(aug_int, aes(.fitted, .resid)) + #plot df just created using augment function
  geom_point(alpha = 0.6) + #transparency
  facet_wrap(~taxon, scales = "free") + #grid with axes varying by plot
  geom_hline(yintercept = 0, linetype = 2) #create dashed line at 0
```

Is there anything concerning with the above plot?

We want these data to be centered around 0, have no trends, and be evenly distributed because the model assumes the response is normally distributed around 0.

Many of these plots seem like they have a pattern.

Now, let's do the same but for the model with  random intercepts and slopes.

```{r, warning=FALSE, message=FALSE}
ggplot(aug_slope, aes(.fitted, .resid)) + 
  geom_point(alpha = 0.6) + 
  facet_wrap(~taxon, scales = "free") +
  geom_hline(yintercept = 0, linetype = 2)
```

This does look better, but G. fortis looks as if it kind of has a curve to it -- this isn't great. 

Let's look at this by itself:
```{r}
filter(aug_slope, taxon == "Geospiza fortis") %>%
  ggplot(aes(.fitted, .resid)) + geom_point() + 
  geom_smooth(se = FALSE)
```

See the curve? Be on the lookout for things like this. For now, we are going to move on. But be aware that you will have to examine your model to check for assumptions and fix any issues. For example, we could fix this by adding a quadratic to the slope.  

Our model still isn't perfect. Modeling is an art, not a science. What is one example of an  assumptions we are making in this model that probably isn't correct? 

We won't go into phylogenetic models but know they exist. 

Let's move on to making publication quality figures. 

